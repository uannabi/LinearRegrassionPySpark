{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"LRExmaple\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = spark.read.format(\"libsvm\").load(\"sample_linear_regression_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|\n",
      "| -7.896274316726144|(10,[0,1,2,3,4,5,...|\n",
      "| -8.464803554195287|(10,[0,1,2,3,4,5,...|\n",
      "| 2.1214592666251364|(10,[0,1,2,3,4,5,...|\n",
      "| 1.0720117616524107|(10,[0,1,2,3,4,5,...|\n",
      "|-13.772441561702871|(10,[0,1,2,3,4,5,...|\n",
      "| -5.082010756207233|(10,[0,1,2,3,4,5,...|\n",
      "|  7.887786536531237|(10,[0,1,2,3,4,5,...|\n",
      "| 14.323146365332388|(10,[0,1,2,3,4,5,...|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|\n",
      "|-0.8995693247765151|(10,[0,1,2,3,4,5,...|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...|\n",
      "|  5.601801561245534|(10,[0,1,2,3,4,5,...|\n",
      "|-3.2256352187273354|(10,[0,1,2,3,4,5,...|\n",
      "| 1.5299675726687754|(10,[0,1,2,3,4,5,...|\n",
      "| -0.250102447941961|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the format that Spark expects. Two columns with the names \"label\" and \"features\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"label\" column then needs to have the numerical label, either a regression numerical value, or a numerical value that matches to a classification grouping. Later on we will talk about unsupervised learning algorithms that by their nature do not use or require a label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature column has inside of it a vector of all the features that belong to that row. Usually what we end up doing is combining the various feature columns we have into a single 'features' column using the data transformations we've learned about.\n",
    "\n",
    "Let's continue working through this simple example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the default values for the featuresCol, labelCol, predictionCol\n",
    "lr = LinearRegression(featuresCol='features', labelCol='label', predictionCol='prediction')\n",
    "\n",
    "# You could also pass in additional parameters for regularization, do the reading \n",
    "# in ISLR to fully understand that, after that its just some simple parameter calls.\n",
    "# Check the documentation with Shift+Tab for more info!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0073350710225801715,0.8313757584337543,-0.8095307954684084,2.441191686884721,0.5191713795290003,1.1534591903547016,-0.2989124112808717,-0.5128514186201779,-0.619712827067017,0.6956151804322931]\n",
      "\n",
      "\n",
      "Intercept:0.14228558260358093\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients: {}\".format(str(lrModel.coefficients))) # For each feature...\n",
    "print('\\n')\n",
    "print(\"Intercept:{}\".format(str(lrModel.intercept)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary = lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "|-11.011130022096554|\n",
      "| 0.9236590911176538|\n",
      "|-4.5957401897776675|\n",
      "|  -20.4201774575836|\n",
      "|-10.339160314788181|\n",
      "|-5.9552091439610555|\n",
      "|-10.726906349283922|\n",
      "|  2.122807193191233|\n",
      "|  4.077122222293811|\n",
      "|-17.316168071241652|\n",
      "| -4.593044343959059|\n",
      "|  6.380476690746936|\n",
      "| 11.320566035059846|\n",
      "|-20.721971774534094|\n",
      "| -2.736692773777401|\n",
      "| -16.66886934252847|\n",
      "|  8.242186378876315|\n",
      "|-1.3723486332690233|\n",
      "|-0.7060332131264666|\n",
      "|-1.1591135969994064|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE: 10.16309157133015\n",
      "r2: 0.027839179518600154\n"
     ]
    }
   ],
   "source": [
    "trainingSummary.residuals.show()\n",
    "print(\"RMSE: {}\".format(trainingSummary.rootMeanSquaredError))\n",
    "print(\"r2: {}\".format(trainingSummary.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = spark.read.format(\"libsvm\").load(\"sample_linear_regression_data.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###split train data and test data\n",
    "train_data, test_data = all_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "|-28.571478869743427|(10,[0,1,2,3,4,5,...|\n",
      "|-28.046018037776633|(10,[0,1,2,3,4,5,...|\n",
      "|-23.487440120936512|(10,[0,1,2,3,4,5,...|\n",
      "|-22.949825936196074|(10,[0,1,2,3,4,5,...|\n",
      "|-21.432387764165806|(10,[0,1,2,3,4,5,...|\n",
      "|-20.212077258958672|(10,[0,1,2,3,4,5,...|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|\n",
      "|-19.872991038068406|(10,[0,1,2,3,4,5,...|\n",
      "| -19.66731861537172|(10,[0,1,2,3,4,5,...|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...|\n",
      "|-18.845922472898582|(10,[0,1,2,3,4,5,...|\n",
      "|-17.803626188664516|(10,[0,1,2,3,4,5,...|\n",
      "|-17.494200356883344|(10,[0,1,2,3,4,5,...|\n",
      "| -17.32672073267595|(10,[0,1,2,3,4,5,...|\n",
      "|-17.065399625876015|(10,[0,1,2,3,4,5,...|\n",
      "|-17.026492264209548|(10,[0,1,2,3,4,5,...|\n",
      "|-16.692207021311106|(10,[0,1,2,3,4,5,...|\n",
      "| -16.08565904102149|(10,[0,1,2,3,4,5,...|\n",
      "| -15.86200932757056|(10,[0,1,2,3,4,5,...|\n",
      "|-15.780685032623301|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
